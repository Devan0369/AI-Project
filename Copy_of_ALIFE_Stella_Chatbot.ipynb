{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of ALIFE_Stella_Chatbot.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPmNZQbXNUdMCiOJKdW2jqG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Devan0369/AI-Project/blob/master/Copy_of_ALIFE_Stella_Chatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gsv_5v7g583V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Description: This is a 'self learning' chatbot program"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZXf8zUd6OBS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Install the package NLTK\n",
        "pip install nltk"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bvDzZxZq6hyL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Install the package newspaper3k\n",
        "pip install newspaper3k"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-WbkdWc7D5r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Import Libraries\n",
        "from newspaper import Article\n",
        "import random\n",
        "import string\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import nltk\n",
        "import numpy as np\n",
        "import warnings"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXX0jDqw8VUZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Ingore any warning messages\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cX_CQCjZ8pNg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Download the packages from NLTK\n",
        "nltk.download('punkt', quiet=True)\n",
        "nltk.download('wordnet', quiet=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6meA4J5A9W2P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Get the article URL\n",
        "article = Article('https://www.mayoclinic.org/diseases-conditions/coronavirus/symptoms-causes/syc-20479963')\n",
        "article.download()\n",
        "article.parse()\n",
        "article.nlp()\n",
        "corpus = article.text\n",
        "\n",
        "#Print the corpus/text\n",
        "print(corpus)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5uFWe2zp-ihR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Tokenization\n",
        "text = corpus\n",
        "sent_tokens = nltk.sent_tokenize(text) #Convert the text into a list of sentences\n",
        "\n",
        "#Print the list of sentences\n",
        "print(sent_tokens)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jBJMKB2l_ZFP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Create a dictornary (key:value) pair to remove punctuations\n",
        "remove_punct_dict = dict(  (ord(punct),None) for punct in string.punctuation)\n",
        "\n",
        "#Print the punctuations\n",
        "print(string.punctuation)\n",
        "\n",
        "#Print the dictionary\n",
        "print(remove_punct_dict)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yJX6k4OUB-CI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Create a function to return a list of lemmatized lower case words after removing punctuations\n",
        "def LemNormalize(text):\n",
        "  return nltk.word_tokenize(text.lower().translate(remove_punct_dict))\n",
        "\n",
        "#Print the tokenization text\n",
        "print(LemNormalize(text))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ApQtsHmjJdr7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Keyword Matching\n",
        "\n",
        "#Greeting Inputs\n",
        "GREETING_INPUTS = [\"hi\",\"hello\",\"hola\",\"greetings\",\"wassup\",\"hey\"]\n",
        "\n",
        "#Greeting Responses back to user\n",
        "GREETING_RESPONSES = [\"howdy\",\"hi\",\"hello\",\"hey\",\"whatsup\",\"hey there\"]\n",
        "\n",
        "#Function to return a random greeting response to a user greeting\n",
        "def greeting(sentence):\n",
        "  #if the user input is a greeting, then return a randomly chosen greeting response\n",
        "  for word in sentence.split():\n",
        "    if word.lower() in GREETING_INPUTS:\n",
        "      return random.choice(GREETING_RESPONSES)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NOGhPkYSNiPR",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PrBTZG7GMfX0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Generate the response\n",
        "def response(user_response):\n",
        "  #The users response / query\n",
        "  #user_response = 'What is Coronavirus'\n",
        "\n",
        "  user_response = user_response.lower() #Make the response lower case\n",
        "\n",
        "  ###Print the user query / response\n",
        "  #print(user_response)\n",
        "\n",
        "  #Set the chatbot response to an empty string\n",
        "  robo_response = ''\n",
        "\n",
        "  #Append the users response to the sentence list\n",
        "  sent_tokens.append(user_response)\n",
        "\n",
        "  ###Print the sentence list after appending the users response\n",
        "  #print(sent_tokens)\n",
        "\n",
        "  #Create a TfidfVectorizer Object\n",
        "  TfidfVec = TfidfVectorizer(tokenizer = LemNormalize, stop_words='english')\n",
        "\n",
        "  #Convert the text to a matrix of TF-IDF features\n",
        "  tfidf = TfidfVec.fit_transform(sent_tokens)\n",
        "\n",
        "  ###Print the TF-IDF Features\n",
        "  #print(tfidf)\n",
        "\n",
        "  #Get the measure of similarity (similarity scores)\n",
        "  vals = cosine_similarity(tfidf[-1], tfidf)\n",
        "\n",
        "  ###Print the similarity scores\n",
        "  #print(vals)\n",
        "\n",
        "  #Get the index of the most similar text/sentense to the user response\n",
        "  idx = vals.argsort()[0][-2]\n",
        "\n",
        "  #Reduce the dimensionality of vals\n",
        "  flat = vals.flatten()\n",
        "\n",
        "  #sort the list in ascending order\n",
        "  flat.sort()\n",
        "\n",
        "  #Get the most similar score to the users response\n",
        "  score = flat[-2]\n",
        "\n",
        "  ###Print the similarity score\n",
        "  #print(score)\n",
        "\n",
        "  #If the variable 'score' is 0 then there is no text to users response\n",
        "  if(score == 0):\n",
        "    robo_response = robo_response+\"I apologise, I don't understand, kindly rephrase your questions.\"\n",
        "  else:\n",
        "    robo_response = robo_response+sent_tokens[idx]\n",
        "\n",
        "  #Print the chatbot response\n",
        "  #print(robo_response)\n",
        "  \n",
        "  #Remove the users response from the senstence token list\n",
        "  sent_tokens.remove(user_response)\n",
        "\n",
        "  return robo_response\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EBiAFniXfNjM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "flag = True\n",
        "print(\"Stella: I am an ALIFE Air Health Bot. I will help you understand all you need about COVID 19. You may exit anytime, just type Bye!\")\n",
        "while(flag == True):\n",
        "  user_response = input()\n",
        "  user_response = user_response.lower()\n",
        "  if(user_response != 'bye'):\n",
        "    if(user_response == 'thanks' or user_response =='thank you'):\n",
        "      flag=False\n",
        "      print(\"Stella: You are welcome !\")\n",
        "    else:\n",
        "      if(greeting(user_response) != None):\n",
        "        print(\"Stella: \"+greeting(user_response))\n",
        "      else:\n",
        "        print(\"Stella: \"+response(user_response))\n",
        "  else:\n",
        "    flag = False\n",
        "    print(\"Stella: See you later !\")\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}